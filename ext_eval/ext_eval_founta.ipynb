{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5qc5wWWQEO36",
    "outputId": "1d470658-98a4-48ea-d6da-f16064b46833"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q8AtWAZqEZVe"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G--eG0iEEk9W"
   },
   "outputs": [],
   "source": [
    "label_map_fountana_org = {'abusive': 0, 'normal': 1, 'hateful': 2, 'spam': 3}\n",
    "hate_map = {0: \"NON HATE\", 1: \"HATE\"}\n",
    "reverse_hate_map = {\"NON HATE\": 0, \"HATE\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iCctayVPF5mz"
   },
   "outputs": [],
   "source": [
    "def hashtag(text):\n",
    "    text = text.group()\n",
    "    hashtag_body = text[1:]\n",
    "    if hashtag_body.isupper():\n",
    "        result = u\"<hashtag> {} <allcaps>\".format(hashtag_body)\n",
    "    else:\n",
    "        result = \" \".join([\"<hashtag>\"] +\n",
    "                          re.split(r\"(?=[A-Z])\", hashtag_body, flags=FLAGS))\n",
    "    return result\n",
    "\n",
    "\n",
    "def allcaps(text):\n",
    "    text = text.group()\n",
    "    return text.lower() + \" <allcaps>\"\n",
    "\n",
    "def tokenize(text):\n",
    "    # Different regex parts for smiley faces\n",
    "    eyes = r\"[8:=;]\"\n",
    "    nose = r\"['`\\-]?\"\n",
    "\n",
    "    # function so code less repetitive\n",
    "    def re_sub(pattern, repl):\n",
    "        return re.sub(pattern, repl, text, flags=FLAGS)\n",
    "\n",
    "    text = re_sub(r\"https?:\\/\\/\\S+\\b|www\\.(\\w+\\.)+\\S*\", \"<url>\")\n",
    "    text = re_sub(r\"/\", \" / \")\n",
    "    text = re_sub(r\"@\\w+\", \"<user>\")\n",
    "    text = re_sub(r\"{}{}[)dD]+|[)dD]+{}{}\".format(eyes, nose, nose, eyes),\n",
    "                  \"<smile>\")\n",
    "    text = re_sub(r\"{}{}p+\".format(eyes, nose), \"<lolface>\")\n",
    "    text = re_sub(r\"{}{}\\(+|\\)+{}{}\".format(eyes, nose, nose, eyes),\n",
    "                  \"<sadface>\")\n",
    "    text = re_sub(r\"{}{}[\\/|l*]\".format(eyes, nose), \"<neutralface>\")\n",
    "    text = re_sub(r\"<3\", \"<heart>\")\n",
    "    text = re_sub(r\"[-+]?[.\\d]*[\\d]+[:,.\\d]*\", \"<number>\")\n",
    "#     text = re_sub(r\"#\\S+\", hashtag)\n",
    "    text = re_sub(r\"([!?.]){2,}\", r\"\\1 <repeat>\")\n",
    "    text = re_sub(r\"\\b(\\S*?)(.)\\2{2,}\\b\", r\"\\1\\2 <elong>\")\n",
    "\n",
    "    ## -- I just don't understand why the Ruby script adds <allcaps> to everything so I limited the selection.\n",
    "    # text = re_sub(r\"([^a-z0-9()<>'`\\-]){2,}\", allcaps)\n",
    "    text = re_sub(r\"([A-Z]){2,}\", allcaps)\n",
    "    text = re.sub(r'[^\\w\\s]','',text)\n",
    "    text = text.strip()\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4jRVt-DhE4Y6"
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    texts = []\n",
    "    labels = []\n",
    "    file = \"fountana_norm_HAclean.json\"\n",
    "    with open(file, 'r') as f:\n",
    "        ft_data = json.load(f)\n",
    "    for each_tweet in ft_data:\n",
    "        tweet = tokenize(ft_data[each_tweet]['text'])\n",
    "        texts.append(tweet)\n",
    "        labels.append(ft_data[each_tweet]['label'])\n",
    "    return texts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rqnelbjNFKDq"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import sys\n",
    "import re\n",
    "\n",
    "FLAGS = re.MULTILINE | re.DOTALL\n",
    "\n",
    "# !pip install tweet-preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "72PdkOWfFOrF",
    "outputId": "d1bc676c-e63f-47b2-d56e-9d9898811997"
   },
   "outputs": [],
   "source": [
    "samples, labels = load_data()\n",
    "assert len(samples) == len(labels)\n",
    "len(labels)\n",
    "plt.hist(labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CdiACy86F35-"
   },
   "outputs": [],
   "source": [
    "# Shuffle the data\n",
    "seed = 1337\n",
    "rng = np.random.RandomState(seed)\n",
    "rng.shuffle(samples)\n",
    "rng = np.random.RandomState(seed)\n",
    "rng.shuffle(labels)\n",
    "\n",
    "# Extract a training & validation split\n",
    "validation_split = 0.2\n",
    "num_validation_samples = int(validation_split * len(samples))\n",
    "train_samples = samples[:-num_validation_samples]\n",
    "val_samples = samples[-num_validation_samples:]\n",
    "train_labels = labels[:-num_validation_samples]\n",
    "val_labels = labels[-num_validation_samples:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REF SOURCE: https://keras.io/examples/nlp/pretrained_word_embeddings/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x9bazFM-FXXT"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "vectorizer = TextVectorization(max_tokens=20000, output_sequence_length=200)\n",
    "text_ds = tf.data.Dataset.from_tensor_slices(train_samples).batch(128)\n",
    "vectorizer.adapt(text_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uGaRNTGsHCzM",
    "outputId": "d8d3c0fb-9025-4a52-baf5-6ff213f238cf"
   },
   "outputs": [],
   "source": [
    "vectorizer.get_vocabulary()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PwDDjoitHIWT"
   },
   "outputs": [],
   "source": [
    "voc = vectorizer.get_vocabulary()\n",
    "word_index = dict(zip(voc, range(len(voc))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cHsJr3QFHL-6",
    "outputId": "69315dc7-e887-4c4c-a56f-1a4ab7a2c0c6"
   },
   "outputs": [],
   "source": [
    "!wget https://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
    "!unzip -q glove.twitter.27B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U84voPkrHhtp",
    "outputId": "16e015a8-0835-4699-f932-ecd50c4a9e89"
   },
   "outputs": [],
   "source": [
    "embedding_dim = 200\n",
    "\n",
    "path_to_glove_file = \"glove.twitter.27B.\"+str(embedding_dim)+\"d.txt\"\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(path_to_glove_file) as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))\n",
    "\n",
    "num_tokens = len(voc) + 2\n",
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uRX43RKJIB27",
    "outputId": "5b44e49e-9e61-43ac-aac3-00a82e8c861b"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "embedding_layer = Embedding(\n",
    "    num_tokens,\n",
    "    embedding_dim,\n",
    "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
    "    trainable=True,\n",
    ")\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "int_sequences_input = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "embedded_sequences = embedding_layer(int_sequences_input)\n",
    "X = layers.SimpleRNN(units=128,recurrent_dropout=0.5, return_sequences=True)(embedded_sequences)\n",
    "X = layers.Attention(use_scale=True)([X,X])\n",
    "X = layers.GlobalAveragePooling1D()(X)\n",
    "X = layers.Dense(128, activation=\"relu\")(X)\n",
    "X = layers.Dropout(0.5)(X)\n",
    "preds = layers.Dense(1, activation=\"sigmoid\")(X)\n",
    "model = keras.Model(int_sequences_input, preds)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A3DiTTmgKwnY"
   },
   "outputs": [],
   "source": [
    "x_train = vectorizer(np.array([[s] for s in train_samples])).numpy()\n",
    "x_val = vectorizer(np.array([[s] for s in val_samples])).numpy()\n",
    "\n",
    "y_train = np.array(train_labels)\n",
    "y_val = np.array(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lUJLeqn7K2Jt",
    "outputId": "6560fa62-b726-438e-d983-7385f8d66dc1"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(), optimizer=tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.001), metrics=[\"acc\",tf.keras.metrics.Precision(),tf.keras.metrics.Recall()]\n",
    ")\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=5, validation_data=[x_val, y_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H4Djkia_LQtR",
    "outputId": "0409bfbf-82bf-4cdf-91f8-020d754e8310"
   },
   "outputs": [],
   "source": [
    "model.evaluate(x_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rI1LSQaOUa8K"
   },
   "outputs": [],
   "source": [
    "def ext_eval_probs(yg,yp):\n",
    "    diff = []\n",
    "    for g,p in zip(yg,yp):\n",
    "        if g[0] >=0.5 and p[0] >=0.5: ## 0 is hate label so we take <0.5\n",
    "            diff.append(g-p)\n",
    "    return np.mean(diff)\n",
    "\n",
    "def return_feature_set(test_samples):\n",
    "    return vectorizer(np.array([[s] for s in test_samples])).numpy()\n",
    "\n",
    "def run_for_test(model_name):\n",
    "    print(model_name)\n",
    "    file = model_name + \"_for_ext_eval.pkl\"\n",
    "    with open(file, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    xg = data[\"ground\"]\n",
    "    xp = data[\"pred\"]\n",
    "    xg = return_feature_set(xg)\n",
    "    xp = return_feature_set(xp)\n",
    "    yg = model.predict(xg)\n",
    "    yp = model.predict(xp)\n",
    "    print(ext_eval_probs(yg,yp))\n",
    "\n",
    "def run_for_test_dict(model_name):\n",
    "    print(model_name)\n",
    "    file = model_name + \"_for_ext_eval.pkl\"\n",
    "    with open(file, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    for k in data:\n",
    "        print(\"------k-----\",k)\n",
    "        xg = data[k][\"ground\"]\n",
    "        xp = data[k][\"pred\"]\n",
    "        xg = return_feature_set(xg)\n",
    "        xp = return_feature_set(xp)\n",
    "        yg = model.predict(xg)\n",
    "        yp = model.predict(xp)\n",
    "        print(ext_eval_probs(yg,yp))\n",
    "\n",
    "def execute_():\n",
    "    run_for_test(\"neutral\")\n",
    "    run_for_test(\"drgpreds\")\n",
    "    run_for_test(\"ntpcares\")\n",
    "    run_for_test_dict(\"fgst\")\n",
    "    run_for_test_dict(\"style\")\n",
    "    run_for_test(\"nacl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "founta_hate_base.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
