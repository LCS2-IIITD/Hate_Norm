{"cells":[{"cell_type":"markdown","metadata":{"id":"SAP07IJ4Wihl"},"source":["# Hate Intensity Prediction (HIP): Regression\n","\n","HIP Module takes a sentence (whether normalised or not) and predicts the hateful intensity of the sentence.\n","\n","The hate intensity is annotated on a scale of 1-10, 0 is reserved for non-hateful sentences which we do not use in our dataset.\n","1 is the lowest hate intensity and 10 is the highest.\n","\n","If using final activation layer is linear then range stays same.\n","If using sigmoid activation layer then input label is normalised to 0-1 range.\n"]},{"cell_type":"markdown","metadata":{"executionInfo":{"elapsed":3404,"status":"ok","timestamp":1647499525907,"user":{"displayName":"Umar Masud","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01610901116861184851"},"user_tz":-330},"id":"3biRGIuXgian","outputId":"11d40729-32dc-4f7b-d81b-c663bcdd39c2"},"source":["## Install these inside colab"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7KN9fX4jhWqK"},"outputs":[],"source":["# !pip install numpy==1.19.5\n","# !pip uninstall tensorflow\n","# !pip install tensorflow==2.2.0\n","# !pip install transformers==3.4.0\n","# !pip install sklearn scipy\n","\n","import numpy\n","assert numpy.__version__==\"1.19.5\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lCKBtamEWihp","executionInfo":{"status":"ok","timestamp":1659508591828,"user_tz":-330,"elapsed":3181,"user":{"displayName":"Sarah Masud","userId":"01097683761850841511"}},"outputId":"c080dd3c-897c-42cd-fe0f-2c0c6eb88ec4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["## The folder is setup to from google drive. If used else only the following lines needs commenting\n","\n","from google.colab import drive\n","\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CyY42zwliaTy"},"outputs":[],"source":["import tensorflow as tf\n","from tqdm import tqdm\n","import numpy as np\n","from transformers import BertTokenizer\n","from transformers import DistilBertTokenizer, RobertaTokenizer, BertConfig, TFBertModel\n","from sklearn.model_selection import train_test_split\n","import pickle\n","import random\n","import sys\n","import math\n","from scipy import stats\n","from scipy.spatial import distance\n","import random\n","import os"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dcG8YhvdWihs"},"outputs":[],"source":["BASE_FOLDER = \"/content/drive/MyDrive/hate_norm_kdd22/\"\n","INPUT_FILE = \"hate_norm_combined.pkl\"\n","OUTPUT_FOLDER = \"hate_intensity_linear_weights_att/\"\n","OUTPUT_FILE = \"hate_int_linear_trans42_ATT\"\n","BERT_MODEL = \"distilbert-base-uncased\"\n","MAX_LENGTH = 128\n","TEST_SIZE = 0.2\n","SEED = 42\n","\n","USE_ATT = True\n","\n","BERT_DROPOUT = 0.2\n","LSTM_UNITS = 50\n","DENSE_UNITS = 50\n","LSTM_DROPOUT = 0.1\n","DENSE_DROPOUT = 0.2\n","EPOCHS = 2 #(Default 10)\n","BATCH_SIZE = 32\n","\n","\n","def random_seed(SEED):\n","    random.seed(SEED)\n","    os.environ['PYTHONHASHSEED'] = str(SEED)\n","    np.random.seed(SEED)\n","    tf.random.set_seed(SEED)\n","\n","random_seed(SEED)"]},{"cell_type":"markdown","metadata":{"id":"qk1pjHGJWiht"},"source":["### Base TRANSFORMER MODEL definitions"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":188,"referenced_widgets":["4a00d3a5e03e4ab39cef6d7cb6b681e2","517c53f11cb54901915b8b5ff51ea1eb","4fbc3f9b0b7746e3abe32e50caa476bd","503c547d013149a6934a8deee64ff8d3","77449a47f0344c99b43ed4cce9ecbbf2","f6fa2a7f94de4da18576897e38b32524","77fbc55d360441228b2fbcc30d931d3e","ed1e81a603924c08a2d95e1a5076e192","0bb77466a84c459584313438f70a7ceb","e014073eacd442759a4921bc4f7f479e","7cf656fa522349da9a8fe4c3fae0622e","b8e122cf7001419eb14bf2978d4aca68","02ca8c27663e4a20930808c9c2a90144","ba156719d0f64f1fa4d46919346b51c1","3474099f1950438282dbd56ba19787dc","1f404fe3a05f434c945cdcfbaea2d776","1c18db5697444b1cab0d75e00b55448a","0a92b5ebf3dc458288c5e4d442a059cd","b0a893bb19674c81bd7b53c8d9d326b5","045b1575a1054f6fab1867248df47a9d","794f8529e96247cab09091fe6b43c616","5b14e6976a194de0b1cee96a85e29944"]},"executionInfo":{"elapsed":11189,"status":"ok","timestamp":1659508618143,"user":{"displayName":"Sarah Masud","userId":"01097683761850841511"},"user_tz":-330},"id":"f6e63Pg2f0DQ","outputId":"9f962c2b-f3ee-4573-d4a6-cdf8206ad5b8"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/363M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a00d3a5e03e4ab39cef6d7cb6b681e2"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFBertModel: ['distilbert', 'activation_13', 'vocab_transform', 'vocab_projector', 'vocab_layer_norm']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some layers of TFBertModel were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['bert']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8e122cf7001419eb14bf2978d4aca68"}},"metadata":{}}],"source":["def tokenize(sentences, tokenizer):\n","    input_ids, input_masks, input_segments = [], [], []\n","    for sentence in tqdm(sentences):\n","        inputs = tokenizer.encode_plus(sentence,\n","                                       add_special_tokens=True,\n","                                       max_length=MAX_LENGTH,\n","                                       pad_to_max_length=True,\n","                                       return_attention_mask=True,\n","                                       return_token_type_ids=True)\n","        input_ids.append(inputs['input_ids'])\n","        input_masks.append(inputs['attention_mask'])\n","        input_segments.append(inputs['token_type_ids'])\n","\n","    return np.asarray(input_ids, dtype='int32'), np.asarray(\n","        input_masks, dtype='int32'), np.asarray(input_segments, dtype='int32')\n","\n","\n","## Define base bert configs\n","config = BertConfig(dropout=BERT_DROPOUT,\n","                    attention_dropout=BERT_DROPOUT,\n","                    output_attentions=True)\n","config.output_hidden_states = False\n","transformer_model = TFBertModel.from_pretrained(BERT_MODEL, config=config)\n","for layer in transformer_model.layers[:3]:  ## We are freezing first 3 layers\n","    layer.trainable = False\n","\n","# Defining tokonizer\n","tokenizer = DistilBertTokenizer.from_pretrained(BERT_MODEL,\n","                                                do_lower_case=True,\n","                                                add_special_tokens=True,\n","                                                max_length=MAX_LENGTH,\n","                                                pad_to_max_length=True)"]},{"cell_type":"markdown","metadata":{"id":"7cb-cLfmWihu"},"source":["### Model Design"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7026,"status":"ok","timestamp":1659508627945,"user":{"displayName":"Sarah Masud","userId":"01097683761850841511"},"user_tz":-330},"id":"nGcE9_IkigmR","outputId":"a7995095-db80-4d68-8021-5e0e663c854b"},"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_token (InputLayer)        [(None, 128)]        0                                            \n","__________________________________________________________________________________________________\n","masked_token (InputLayer)       [(None, 128)]        0                                            \n","__________________________________________________________________________________________________\n","tf_bert_model (TFBertModel)     ((None, 128, 768), ( 109482240   input_token[0][0]                \n","__________________________________________________________________________________________________\n","bidirectional (Bidirectional)   (None, 128, 100)     327600      tf_bert_model[0][0]              \n","__________________________________________________________________________________________________\n","attention (Attention)           (None, 128, 100)     1           bidirectional[0][0]              \n","                                                                 bidirectional[0][0]              \n","__________________________________________________________________________________________________\n","global_max_pooling1d (GlobalMax (None, 100)          0           attention[0][0]                  \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 50)           5050        global_max_pooling1d[0][0]       \n","__________________________________________________________________________________________________\n","dropout_37 (Dropout)            (None, 50)           0           dense[0][0]                      \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 1)            51          dropout_37[0][0]                 \n","==================================================================================================\n","Total params: 109,814,942\n","Trainable params: 332,702\n","Non-trainable params: 109,482,240\n","__________________________________________________________________________________________________\n"]}],"source":["input_ids_in = tf.keras.layers.Input(shape=(MAX_LENGTH, ),\n","                                     name='input_token',\n","                                     dtype='int32')\n","input_masks_in = tf.keras.layers.Input(shape=(MAX_LENGTH, ),\n","                                       name='masked_token',\n","                                       dtype='int32')\n","embedding_layer = transformer_model(input_ids_in,\n","                                    attention_mask=input_masks_in)[0]\n","X = tf.keras.layers.Bidirectional(\n","    tf.keras.layers.LSTM(LSTM_UNITS,\n","                         return_sequences=True,\n","                         dropout=LSTM_DROPOUT,\n","                         recurrent_dropout=LSTM_DROPOUT,\n","                         kernel_initializer='normal'))(embedding_layer)\n","if USE_ATT:\n","    X = tf.keras.layers.Attention(use_scale=True)([X, X])  # Use attention.\n","X = tf.keras.layers.GlobalMaxPool1D()(X)\n","X = tf.keras.layers.Dense(DENSE_UNITS,\n","                          activation='relu',\n","                          kernel_initializer='normal')(X)\n","X = tf.keras.layers.Dropout(DENSE_DROPOUT)(X)\n","X = tf.keras.layers.Dense(\n","    1,\n","    activation='linear',  # Can be with activation=\"sigmoid\" here.\n","    kernel_initializer='normal')(X)\n","model = tf.keras.Model(inputs=[input_ids_in, input_masks_in], outputs=X)\n","model.compile(\n","    optimizer='adam',\n","    loss='mean_squared_error',  # Treat HIP as a regression problem\n","    metrics=['acc', tf.keras.metrics.RootMeanSquaredError()])\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"bugZ2DEOWihw"},"source":["### Dataset prep"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tkxwym01Wihw","executionInfo":{"status":"ok","timestamp":1659508638138,"user_tz":-330,"elapsed":5622,"user":{"displayName":"Sarah Masud","userId":"01097683761850841511"}},"outputId":"03a1088b-4e07-4294-e6b5-71d3635222d9"},"outputs":[{"output_type":"stream","name":"stderr","text":["  0%|          | 0/4844 [00:00<?, ?it/s]Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","100%|██████████| 4844/4844 [00:03<00:00, 1493.20it/s]\n","100%|██████████| 1212/1212 [00:01<00:00, 824.54it/s]\n"]}],"source":["with open(BASE_FOLDER + INPUT_FILE, 'rb') as f:\n","    input_data = pickle.load(f)\n","\n","intensity_value = []\n","hate_sentences = []\n","\n","for i in range(len(input_data)):\n","    intensity_value.append(int(input_data['Original_Intensity'][i]))\n","    hate_sentences.append(input_data['Sentence'][i])\n","    intensity_value.append(int(input_data['Normalized_Intensity'][i]))\n","    hate_sentences.append(input_data['Normalized_Sentence'][i])\n","\n","c = list(zip(intensity_value, hate_sentences))\n","random.shuffle(c)\n","intensity_value, hate_sentences = zip(*c)\n","\n","X_tr, X_te, y_tr, y_te = train_test_split(hate_sentences,\n","                                          intensity_value,\n","                                          test_size=TEST_SIZE,\n","                                          random_state=1)\n","\n","train_input_ids, train_input_masks, train_input_segment = tokenize(\n","    X_tr, tokenizer)\n","test_input_ids, test_input_masks, test_input_segment = tokenize(\n","    X_te, tokenizer)\n","y_tr = np.asarray(y_tr)\n","y_te = np.asarray(y_te)"]},{"cell_type":"markdown","metadata":{"id":"LSRZbOhdWihw"},"source":["### Train and evlauate"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WDKVTxtQWihx","executionInfo":{"status":"ok","timestamp":1659508989014,"user_tz":-330,"elapsed":345275,"user":{"displayName":"Sarah Masud","userId":"01097683761850841511"}},"outputId":"1fc8e2ca-c4b5-4b92-c8bb-9400026dcfe3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n","137/137 [==============================] - 143s 1s/step - loss: 7.5775 - acc: 0.0069 - root_mean_squared_error: 2.7527 - val_loss: 4.6020 - val_acc: 0.0021 - val_root_mean_squared_error: 2.1452\n","Epoch 2/2\n","137/137 [==============================] - 141s 1s/step - loss: 4.6722 - acc: 0.0071 - root_mean_squared_error: 2.1615 - val_loss: 4.6006 - val_acc: 0.0021 - val_root_mean_squared_error: 2.1449\n","TEST split 0.2\n","38/38 [==============================] - 12s 323ms/step - loss: 4.2039 - acc: 0.0058 - root_mean_squared_error: 2.0503\n","[4.203866481781006, 0.005775577388703823, 2.050333261489868]\n","pear (-0.10515755563246845, 0.00024509868105208866)\n","cosine 0.9380874416063923\n"]}],"source":["model.fit(x=[train_input_ids, train_input_masks],\n","          y=y_tr,\n","          epochs=EPOCHS,\n","          validation_split=0.1,\n","          batch_size=BATCH_SIZE)\n","\n","print(\"TEST split\", TEST_SIZE)\n","results = model.evaluate(x=[test_input_ids, test_input_masks], y=y_te)\n","print(results)\n","result = model.predict(x=[test_input_ids, test_input_masks])\n","result = np.array(result, dtype=np.float)\n","result = result.flatten()\n","print(\"pear\", stats.pearsonr(result, y_te))\n","print(\"cosine\", 1 - distance.cosine(result, y_te))"]},{"cell_type":"markdown","source":["### To save model\n","Run\n","```\n","# model.save_weights(BASE_FOLDER + OUTPUT_FOLDER + OUTPUT_FILE)\n","```"],"metadata":{"id":"CDhskIwCWvHh"}},{"cell_type":"markdown","metadata":{"id":"Gouti7v7Wihx"},"source":["### To load model\n","Run upto the cells up till `model_design` part and then do\n","```\n","model.load_weights(BASE_FOLDER+OUTPUT_FOLDER+OUTPUT_FILE)\n","```"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"hate_intensity_prediction.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"4a00d3a5e03e4ab39cef6d7cb6b681e2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_517c53f11cb54901915b8b5ff51ea1eb","IPY_MODEL_4fbc3f9b0b7746e3abe32e50caa476bd","IPY_MODEL_503c547d013149a6934a8deee64ff8d3"],"layout":"IPY_MODEL_77449a47f0344c99b43ed4cce9ecbbf2"}},"517c53f11cb54901915b8b5ff51ea1eb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f6fa2a7f94de4da18576897e38b32524","placeholder":"​","style":"IPY_MODEL_77fbc55d360441228b2fbcc30d931d3e","value":"Downloading: 100%"}},"4fbc3f9b0b7746e3abe32e50caa476bd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ed1e81a603924c08a2d95e1a5076e192","max":363423424,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0bb77466a84c459584313438f70a7ceb","value":363423424}},"503c547d013149a6934a8deee64ff8d3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e014073eacd442759a4921bc4f7f479e","placeholder":"​","style":"IPY_MODEL_7cf656fa522349da9a8fe4c3fae0622e","value":" 363M/363M [00:06&lt;00:00, 53.6MB/s]"}},"77449a47f0344c99b43ed4cce9ecbbf2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f6fa2a7f94de4da18576897e38b32524":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77fbc55d360441228b2fbcc30d931d3e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ed1e81a603924c08a2d95e1a5076e192":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0bb77466a84c459584313438f70a7ceb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e014073eacd442759a4921bc4f7f479e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7cf656fa522349da9a8fe4c3fae0622e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b8e122cf7001419eb14bf2978d4aca68":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_02ca8c27663e4a20930808c9c2a90144","IPY_MODEL_ba156719d0f64f1fa4d46919346b51c1","IPY_MODEL_3474099f1950438282dbd56ba19787dc"],"layout":"IPY_MODEL_1f404fe3a05f434c945cdcfbaea2d776"}},"02ca8c27663e4a20930808c9c2a90144":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1c18db5697444b1cab0d75e00b55448a","placeholder":"​","style":"IPY_MODEL_0a92b5ebf3dc458288c5e4d442a059cd","value":"Downloading: 100%"}},"ba156719d0f64f1fa4d46919346b51c1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b0a893bb19674c81bd7b53c8d9d326b5","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_045b1575a1054f6fab1867248df47a9d","value":231508}},"3474099f1950438282dbd56ba19787dc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_794f8529e96247cab09091fe6b43c616","placeholder":"​","style":"IPY_MODEL_5b14e6976a194de0b1cee96a85e29944","value":" 232k/232k [00:00&lt;00:00, 424kB/s]"}},"1f404fe3a05f434c945cdcfbaea2d776":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c18db5697444b1cab0d75e00b55448a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a92b5ebf3dc458288c5e4d442a059cd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b0a893bb19674c81bd7b53c8d9d326b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"045b1575a1054f6fab1867248df47a9d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"794f8529e96247cab09091fe6b43c616":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b14e6976a194de0b1cee96a85e29944":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}