{"cells":[{"cell_type":"markdown","metadata":{"id":"gWa9tPQKbO_B"},"source":["# Hate Span Prediction (HSP): Multi-class Classification\n","\n","HSP Module takes a non-normalised sentence and predicts hateful spans within the spans. These spans are initially manualled annotated via the BIO notation. \n","For evaluation we get the classic P/R/F1 but through the lense of POS tagged sequence eval setup"]},{"cell_type":"markdown","metadata":{"id":"yw0VaNLHbO_I"},"source":["## IMP NOTE: This is the TF-2 Version of HSP using Glove as based embedding."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tqwa-r8LM5Y-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659510436428,"user_tz":-330,"elapsed":2194,"user":{"displayName":"Sarah Masud","userId":"01097683761850841511"}},"outputId":"aca14ac7-9506-4c36-dfb8-467f8eb1ddd7"},"outputs":[{"output_type":"stream","name":"stdout","text":["2.2.0\n"]}],"source":["# !pip install numpy==1.19.5\n","# !pip uninstall tensorflow\n","# !pip install tensorflow==2.2.0\n","# !pip install tensorflow-addons==0.10.0\n","# !pip install sklearn scipy\n","# !pip install seqeval\n","\n","import numpy\n","assert numpy.__version__==\"1.19.5\"\n","\n","import tensorflow as tf\n","\n","print(tf.__version__)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j6ejmlLXbO_G","executionInfo":{"status":"ok","timestamp":1659510471916,"user_tz":-330,"elapsed":29239,"user":{"displayName":"Sarah Masud","userId":"01097683761850841511"}},"outputId":"f1826e1a-1d8d-4154-86e0-3651f17d3d7a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["## The folder is setup to from google drive. If used else only the following lines needs commenting\n","\n","from google.colab import drive\n","\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sbqAqZFOhEn5"},"outputs":[],"source":["import random\n","import pickle\n","import json\n","import sys\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n","from tensorflow.keras.layers import Embedding\n","import os\n","from seqeval.metrics import precision_score, recall_score, f1_score, classification_report"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wermbWyabO_K"},"outputs":[],"source":["BASE_FOLDER = \"/content/drive/MyDrive/hate_norm_kdd22/\"\n","INPUT_FILE = \"crf_datafinalkdd22.p\"\n","OUTPUT_FOLDER = \"hate_span_glove_crf_tf2_weight\"\n","OUTPUT_FILE = \"hate_span_glove_crf_tf2\"\n","GLOVE_EMB_TRAINED = \"glove_emb_crf_weights.pkl\"\n","GLOVE_VECTORIZER_TRAINED = \"glove_crf_tv_layer.pkl\"\n","\n","## Note we are using an existing CRF module, source is currently untraceable, but it was taken from Github.\n","CRF_FILE = \"crf.py\"\n","GLOVE_EMB = 200\n","MAX_LEN = 60\n","TEST_SIZE = 448\n","\n","N_CRF_TAGS = 3\n","LSTM_UNITS = 512\n","DENSE_UNITS = 50\n","LSTM_DROPOUT = 0.2\n","DENSE_DROPOUT = 0.2\n","EPOCHS = 2 #(Default 5, check!)\n","BATCH_SIZE = 32\n","SEED = 42\n","\n","def random_seed(SEED):\n","    random.seed(SEED)\n","    os.environ['PYTHONHASHSEED'] = str(SEED)\n","    np.random.seed(SEED)\n","    tf.random.set_seed(SEED)\n","\n","\n","random_seed(SEED)\n","\n","## Note we are using an existing CRF module, source is currently untraceable, but it was taken from Github.\n","sys.path.append(BASE_FOLDER + CRF_FILE)\n","!cp /content/drive/MyDrive/hate_norm_kdd22/crf.py . # Done for colab\n","from crf import CRF as CRF_lib"]},{"cell_type":"markdown","metadata":{"id":"XMNN-4oibO_L"},"source":["### Data Prep"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tt15-EXaiTyS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659510492841,"user_tz":-330,"elapsed":3440,"user":{"displayName":"Sarah Masud","userId":"01097683761850841511"}},"outputId":"1cd4d5b4-a417-40df-c1af-dd75159c68df"},"outputs":[{"output_type":"stream","name":"stdout","text":["2579 448\n","2579 448\n","2579 448\n","2579 448\n","(2579, 60, 3) (448, 60, 3)\n","Len Vocab 9754\n"]}],"source":["with open(BASE_FOLDER + INPUT_FILE, \"rb\") as f:\n","    input_data = pickle.load(f)\n","\n","words = list(set(input_data[\"Word\"].values))\n","words.append(\"__PAD__\")\n","n_words = len(words)\n","tags = list(set(input_data[\"Tag\"].values))\n","n_tags = len(tags)\n","assert n_tags == N_CRF_TAGS\n","postags = list(set(input_data['POS'].values))\n","postags.append(\"XX\")\n","n_postags = len(postags)\n","\n","\n","class SentenceGetter(object):\n","    def __init__(self, data):\n","        self.n_sent = 1\n","        self.data = data\n","        self.empty = False\n","        agg_func = lambda s: [(w, p, t) for w, p, t in zip(\n","            s[\"Word\"].values.tolist(), s[\"POS\"].values.tolist(), s[\"Tag\"].\n","            values.tolist())]\n","        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n","        self.sentences = [s for s in self.grouped]\n","\n","    def get_next(self):\n","        try:\n","            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n","            self.n_sent += 1\n","            return s\n","        except:\n","            return None\n","\n","\n","getter = SentenceGetter(input_data)\n","sent = getter.get_next()\n","sentences = getter.sentences\n","\n","tag2idx = {t: i for i, t in enumerate(tags)}\n","postag2idx = {t: i for i, t in enumerate(postags)}\n","X = [[w[0] for w in s] for s in sentences]\n","\n","new_X = []\n","for seq in X:\n","    new_seq = []\n","    for i in range(MAX_LEN):\n","        try:\n","            new_seq.append(seq[i])\n","        except:\n","            new_seq.append(\"__PAD__\")\n","    new_X.append(new_seq)\n","X = new_X\n","\n","y = [[tag2idx[w[2]] for w in s] for s in sentences]\n","y = keras.preprocessing.sequence.pad_sequences(maxlen=MAX_LEN,\n","                                               sequences=y,\n","                                               padding=\"post\",\n","                                               value=tag2idx[\"O\"])\n","y = [keras.utils.to_categorical(i, num_classes=N_CRF_TAGS) for i in y]\n","\n","ypos = [[postag2idx[w[1]] for w in s] for s in sentences]\n","ypos = keras.preprocessing.sequence.pad_sequences(maxlen=MAX_LEN,\n","                                                  sequences=ypos,\n","                                                  padding=\"post\",\n","                                                  value=postag2idx[\"XX\"])\n","\n","X_tr, X_te, y_tr, y_te, ypos_tr, ypos_te = train_test_split(\n","    X, y, ypos, test_size=TEST_SIZE, random_state=SEED)\n","print(len(X_tr), len(X_te))\n","print(len(y_tr), len(y_te))\n","print(len(ypos_tr), len(ypos_te))\n","\n","X_tr_vectorize = [\" \".join(X_tr[i]) for i in range(len(X_tr))]\n","X_te_vectorize = [\" \".join(X_te[i]) for i in range(len(X_te))]\n","print(len(X_tr_vectorize), len(X_te_vectorize))\n","y_tr = np.asarray(y_tr)\n","y_te = np.asarray(y_te)\n","print(y_tr.shape, y_te.shape)\n","\n","vectorizer = TextVectorization(max_tokens=None,\n","                               output_sequence_length=MAX_LEN,\n","                               standardize=None)\n","text_ds = tf.data.Dataset.from_tensor_slices(X_tr_vectorize)\n","vectorizer.adapt(text_ds.batch(128))\n","\n","voc = vectorizer.get_vocabulary()\n","voc_bs = [tf.compat.as_str_any(i) for i in voc]\n","word_index = dict(zip(voc_bs, range(len(voc))))\n","print(\"Len Vocab\", len(voc))\n","\n","X_train = vectorizer(np.array([[s] for s in X_tr_vectorize])).numpy()\n","X_test = vectorizer(np.array([[s] for s in X_te_vectorize])).numpy()"]},{"cell_type":"markdown","metadata":{"id":"4mGy7NuQbO_O"},"source":["### Set up glove embeddings"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BbOPCopNbO_P","executionInfo":{"status":"ok","timestamp":1659511035142,"user_tz":-330,"elapsed":537070,"user":{"displayName":"Sarah Masud","userId":"01097683761850841511"}},"outputId":"74945c84-92ac-4459-d107-509532de4617"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-08-03 07:08:40--  http://nlp.stanford.edu/data/glove.twitter.27B.zip\n","Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://nlp.stanford.edu/data/glove.twitter.27B.zip [following]\n","--2022-08-03 07:08:40--  https://nlp.stanford.edu/data/glove.twitter.27B.zip\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: https://downloads.cs.stanford.edu/nlp/data/glove.twitter.27B.zip [following]\n","--2022-08-03 07:08:41--  https://downloads.cs.stanford.edu/nlp/data/glove.twitter.27B.zip\n","Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n","Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1520408563 (1.4G) [application/zip]\n","Saving to: ‘glove.twitter.27B.zip’\n","\n","glove.twitter.27B.z 100%[===================>]   1.42G  3.28MB/s    in 8m 17s  \n","\n","2022-08-03 07:16:58 (2.92 MB/s) - ‘glove.twitter.27B.zip’ saved [1520408563/1520408563]\n","\n"]}],"source":["## Download and unzip the embeddings if using for 1st time. Y\n","##You can also save and load from your specified path once you save in your folder\n","\n","!wget http://nlp.stanford.edu/data/glove.twitter.27B.zip\n","!unzip -q glove.twitter.27B.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bfOqTAxybO_Q","executionInfo":{"status":"ok","timestamp":1659511428524,"user_tz":-330,"elapsed":52496,"user":{"displayName":"Sarah Masud","userId":"01097683761850841511"}},"outputId":"ef5e70af-d1b8-410f-fe66-fecdd231178d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1193514 word vectors.\n","Converted 6046 words (3708 misses)\n"]}],"source":["path_to_glove_file = \"glove.twitter.27B.\" + str(GLOVE_EMB) + \"d.txt\"\n","embeddings_index = {}\n","with open(path_to_glove_file) as f:\n","    for line in f:\n","        word, coefs = line.split(maxsplit=1)\n","        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n","        embeddings_index[word] = coefs\n","\n","print(\"Found %s word vectors.\" % len(embeddings_index))\n","\n","num_tokens = len(voc) + 2\n","hits = 0\n","misses = 0\n","\n","# Prepare embedding matrix\n","embedding_matrix = np.zeros((num_tokens, GLOVE_EMB))\n","for word, i in word_index.items():\n","    embedding_vector = embeddings_index.get(word)\n","    if embedding_vector is not None:\n","\n","        embedding_matrix[i] = embedding_vector\n","        hits += 1\n","    else:\n","        # Words not found in embedding index will be have random embedding.\n","        # This includes the representation for \"padding\" and \"OOV\"\n","        random_num1 = np.random.rand(GLOVE_EMB)\n","        random_num2 = np.random.rand(GLOVE_EMB)\n","        embedding_vector = [\n","            r1 if r2 < 0.5 else -1 * r1\n","            for r1, r2 in zip(random_num1, random_num2)\n","        ]\n","        # print(embedding_vector)\n","        embedding_matrix[i] = embedding_vector\n","        misses += 1\n","print(\"Converted %d words (%d misses)\" % (hits, misses))\n","\n","embedding_layer = Embedding(\n","    num_tokens,\n","    GLOVE_EMB,\n","    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n","    trainable=True,\n",")"]},{"cell_type":"markdown","metadata":{"id":"_7rUlLE7bO_R"},"source":["## Model prep"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KMSvA-rryKEM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659511431634,"user_tz":-330,"elapsed":3137,"user":{"displayName":"Sarah Masud","userId":"01097683761850841511"}},"outputId":"ec4b4014-4e51-4afe-c9d6-33b7e7eac468"},"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Layer lstm1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 60)]         0                                            \n","__________________________________________________________________________________________________\n","embedding_2 (Embedding)         (None, 60, 200)      1951200     input_1[0][0]                    \n","__________________________________________________________________________________________________\n","bidirectional (Bidirectional)   (None, 60, 1024)     2920448     embedding_2[0][0]                \n","__________________________________________________________________________________________________\n","bidirectional_1 (Bidirectional) (None, 60, 1024)     2920448     embedding_2[0][0]                \n","__________________________________________________________________________________________________\n","add (Add)                       (None, 60, 1024)     0           bidirectional[0][0]              \n","                                                                 bidirectional_1[0][0]            \n","__________________________________________________________________________________________________\n","time_distributed (TimeDistribut (None, 60, 50)       51250       add[0][0]                        \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 60, 3)        153         time_distributed[0][0]           \n","__________________________________________________________________________________________________\n","crf (CRF)                       (None, 60, 3)        9           dense_1[0][0]                    \n","==================================================================================================\n","Total params: 7,843,508\n","Trainable params: 7,843,508\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}],"source":["crf = CRF_lib(N_CRF_TAGS, sparse_target=True)\n","\n","input_text = keras.Input(shape=(MAX_LEN, ), dtype=tf.float32)\n","embedding = Embedding(\n","    num_tokens,\n","    GLOVE_EMB,\n","    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n","    trainable=True,\n",")(input_text)\n","x = keras.layers.Bidirectional(\n","    keras.layers.LSTM(units=LSTM_UNITS,\n","                      return_sequences=True,\n","                      recurrent_dropout=LSTM_DROPOUT,\n","                      dropout=LSTM_DROPOUT,\n","                      name='lstm1'))(embedding)\n","x_rnn = keras.layers.Bidirectional(\n","    keras.layers.LSTM(units=LSTM_UNITS,\n","                      return_sequences=True,\n","                      recurrent_dropout=LSTM_DROPOUT,\n","                      dropout=LSTM_DROPOUT))(embedding)\n","x = keras.layers.add([x, x_rnn])  # residual connection to the first biLSTM\n","base_model = keras.layers.TimeDistributed(\n","    keras.layers.Dense(DENSE_UNITS, activation=\"relu\"))(x)\n","base_model = keras.layers.Dense(N_CRF_TAGS)(base_model)\n","out = crf(base_model)\n","model = keras.models.Model(input_text, out)\n","model.compile('adam', loss=crf.loss, metrics=[crf.accuracy])\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"vn3qD9SIbO_S"},"source":["### Train and Eval"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qi-Nx5nm0Au-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659512455920,"user_tz":-330,"elapsed":134291,"user":{"displayName":"Sarah Masud","userId":"01097683761850841511"}},"outputId":"b908c288-f845-4408-d3ff-c26353799194"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n","73/73 [==============================] - 67s 913ms/step - loss: 4.5378 - viterbi_accuracy: 0.9714 - val_loss: 36.1833 - val_viterbi_accuracy: 0.9415\n","Epoch 2/2\n","73/73 [==============================] - 63s 857ms/step - loss: 3.7111 - viterbi_accuracy: 0.9771 - val_loss: 35.4319 - val_viterbi_accuracy: 0.9411\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O-RB seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O-IN seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O-PRP seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O-VBP seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O-VBG seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O-PRP$ seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O-NN seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O-. seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O-XX seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O-JJ seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O-TO seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O-VB seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O-DT seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O-JJR seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O-EX seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O-VBZ seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O-WP seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O-RBS seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O-CC seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O-NNS seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O-VBD seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O-VBN seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O-NNP seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O-'' seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O-POS seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O-MD seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O-: seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O-CD seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O-WDT seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O-JJS seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O-WRB seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O-PDT seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O-RP seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O-NNPS seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O-$ seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O-, seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O-( seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O-) seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O-RBR seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O-UH seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O-SYM seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O-FW seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O-# seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O-`` seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           ,      0.000     0.000     0.000         1\n","           .      1.000     0.250     0.400         4\n","          CC      0.583     0.467     0.519        30\n","          CD      0.667     0.500     0.571         4\n","          DT      0.600     0.273     0.375        66\n","          EX      0.000     0.000     0.000         1\n","          IN      0.559     0.306     0.396        62\n","          JJ      0.718     0.575     0.639       186\n","         JJR      1.000     1.000     1.000         6\n","         JJS      0.000     0.000     0.000         1\n","          MD      0.000     0.000     0.000        10\n","          NN      0.705     0.639     0.670       457\n","         NNP      0.620     0.571     0.595       140\n","        NNPS      0.000     0.000     0.000         2\n","         NNS      0.810     0.693     0.747       179\n","         PDT      1.000     1.000     1.000         1\n","         PRP      0.833     0.185     0.303        27\n","        PRP$      0.727     0.400     0.516        20\n","          RB      0.692     0.383     0.493        47\n","         RBR      0.000     0.000     0.000         0\n","          RP      0.400     0.286     0.333         7\n","          TO      0.333     0.154     0.211        13\n","          VB      0.727     0.526     0.611        76\n","         VBD      0.760     0.655     0.704        29\n","         VBG      0.714     0.517     0.600        29\n","         VBN      0.765     0.406     0.531        32\n","         VBP      0.750     0.639     0.690        61\n","         VBZ      0.875     0.412     0.560        34\n","         WDT      0.500     0.250     0.333         4\n","          WP      1.000     1.000     1.000         1\n","         WRB      0.000     0.000     0.000         2\n","\n","   micro avg      0.706     0.549     0.618      1532\n","   macro avg      0.559     0.390     0.445      1532\n","weighted avg      0.699     0.549     0.607      1532\n","\n"]}],"source":["model.fit(X_train,\n","          y_tr,\n","          batch_size=BATCH_SIZE,\n","          validation_split=0.1,\n","          epochs=EPOCHS)\n","\n","y_pred = model.predict(X_test)\n","\n","idx2tag = {i: w for w, i in tag2idx.items()}\n","\n","\n","def pred2label(pred):\n","    out = []\n","    for pred_i in pred:\n","        out_i = []\n","        for p in pred_i:\n","            p_i = np.argmax(p)\n","            out_i.append(idx2tag[p_i].replace(\"__PAD__\", \"O\"))\n","        out.append(out_i)\n","    return out\n","\n","\n","def test2label(pred):\n","    out = []\n","    for pred_i in pred:\n","        out_i = []\n","        for p in pred_i:\n","            out_i.append(idx2tag[p].replace(\"__PAD__\", \"O\"))\n","        out.append(out_i)\n","    return out\n","\n","\n","pred_labels = pred2label(y_pred)\n","test_labels = test2label(np.argmax(y_te, -1))\n","\n","posidx2tag = {i: w for w, i in postag2idx.items()}\n","\n","true_labels_pos = []\n","pred_labels_pos = []\n","for idx in range(len(test_labels)):\n","    true = test_labels[idx]\n","    pred = pred_labels[idx]\n","    new_true = []\n","    new_pred = []\n","    for i, pt in enumerate(ypos_te[idx]):\n","        pt = posidx2tag[pt]\n","        new_true.append(true[i] + \"-\" + pt)\n","        new_pred.append(pred[i] + \"-\" + pt)\n","    true_labels_pos.append(new_true)\n","    pred_labels_pos.append(new_pred)\n","\n","## IMP NOTE: This classification report is from the seqeval library and NOT SKLEARN\n","\n","print(\n","    classification_report(true_labels_pos,\n","                          pred_labels_pos,\n","                          digits=N_CRF_TAGS))"]},{"cell_type":"markdown","metadata":{"id":"PPxUec5sbO_T"},"source":["### Model Saving"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8YWEjeaSs5K_"},"outputs":[],"source":["# ## Save the trained glove embeddings\n","\n","# for layer in model.layers:\n","#     name = layer.get_config().get('name')\n","#     if \"embedding\" in name:\n","#         print(layer.get_weights()[0].shape == (num_tokens, glove_emd))\n","#         with open(BASE_FOLDER + GLOVE_EMB_TRAINED, \"wb\") as f:\n","#             pickle.dump(layer.get_weights(), f)\n","#         break\n","\n","# ## Save the text vectorizers\n","# pickle.dump(\n","#     {\n","#         'config': vectorizer.get_config(),\n","#         'weights': vectorizer.get_weights()\n","#     }, open(BASE_FOLDER + GLOVE_VECTORIZER_TRAINED, \"wb\"))\n","\n","# model.save_weights(BASE_FOLDER + OUTPUT_FOLDER + OUTPUT_FILE)\n","\n","# ## Save the tag-id maps\n","# with open(BASE_FOLDER + \"posidx2tag_glove\", \"w\") as f:\n","#     json.dump(posidx2tag)\n","# with open(BASE_FOLDER + \"idx2tag_glove\", \"w\") as f:\n","#     json.dump(idx2tag)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"hate_span_pred_glove.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}